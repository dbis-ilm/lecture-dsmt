{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Apriori-Algorithmus\n",
    "\n",
    "Der Apriori-Algorithmus nutzt die Monotonie-Eigenschaft, um die Anzahl der Kandidaten für häufige Itemsets frühzeitig zu verringern. In diesem Abschnitt soll sowohl die Monotonie-Eigenschaft wie auch der Apriori-Algorithmus am Beispiel gezeigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from tui_dsmt.fpm import Itemset, receipts, numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Inhaltsverzeichnis\n",
    "- [Monotonie-Eigenschaft](#Monotonie-Eigenschaft)\n",
    "- [Bestimmung der häufigen Itemsets](#Bestimmung-der-häufigen-Itemsets)\n",
    "- [Einfluss des minimalen Supports](#Einfluss-des-minimalen-Supports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Monotonie-Eigenschaft\n",
    "Betrachten Sie zuerst noch einmal die Transaktionen, die wir durch Einkäufe aufgezeichnet haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "receipts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Monotonie-Eigenschaft besagt nun, dass jede Teilmenge eines häufig auftretenden Itemsets selbst häufig sein muss. Kommt also die Kombination `{Brot, Milch}` in $40\\%$ aller Transaktionen vor, so kommen die Teilmengen `{Brot}` und `{Milch}` ebenfalls in **mindestens** $40\\%$ aller Transaktionen vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "Itemset('Brot', 'Milch').count_in(receipts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "Itemset('Milch').count_in(receipts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Häufigkeit der Obermenge stellt dabei eine untere Schranke dar. Die kleineren Mengen können einzeln selbstverständlich häufiger vorkommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "Itemset('Brot').count_in(receipts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Anwenden lässt sich das Prinzip nicht nur auf einelementige Teilmengen zweielementiger Mengen. Stattdessen kann es für beliebig große Itemsets verwendet werden.\n",
    "\n",
    "Im Folgenden verwenden wir jedoch nicht das Monotonie-Prinzip, sondern dessen Umkehrung: Wenn eine Menge nicht häufig ist, dann ist auch deren Obermenge nicht häufig. Wird Brot also nur einmal gekauft, kann die Kombination aus Brot und Milch nicht zweimal verkauft worden sein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Bestimmung der häufigen Itemsets\n",
    "Der Apriori Algorithmus versucht nun, häufige Itemsets aus kleineren häufigen Itemsets zu erstellen. Dabei werden mit Hilfe eines minimalen Support-Wertes möglichst früh Itemsets ausgeschlossen, deren Kombinationen laut der Monotonie-Eigenschaft ebenfalls nicht mehr in Betracht zu ziehen sind. Der Algorithmus wird an folgendem Beispiel dargestellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Außerordentlich relevant für den Algorithmus ist die Wahl des minimalen Supports. Wir setzten den Wert zunächst auf $0.5$ und kommen am Ende noch einmal auf die Wahl dieses Wertes zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "support_threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Bestimmung der einelementigen Teilmengen\n",
    "Bevor wir den Algorithmus betrachten, benötigen wir allerdings noch andere Funktionen. Beginnen wir mit dem Suchen aller einelementigen Itemsets, die den minimalen Support überschreiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def itemsets1(transactions, min_supp):\n",
    "    # leere Abbildung anlegen\n",
    "    C1 = {}\n",
    "\n",
    "    # alle Transaktionen durchgehen\n",
    "    for _, items in transactions:\n",
    "        # alle Elemente der Transaktion betrachten\n",
    "        for element in items:\n",
    "            # Element zur Abbildung hinzufügen\n",
    "            # bzw. Anzahl um 1 erhöhen\n",
    "            if element not in C1:\n",
    "                C1[element] = 1\n",
    "            else:\n",
    "                C1[element] += 1\n",
    "\n",
    "    # Elemente nach minimalem Support filtern\n",
    "    # und in Itemset umwandeln\n",
    "    return set(Itemset(item) for item, count in C1.items()\n",
    "               if count / len(transactions) >= min_supp)\n",
    "\n",
    "\n",
    "L1 = itemsets1(numbers, support_threshold)\n",
    "L1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Menge $L_k$ enthält immer die Menge aller häufig vorkommenden Itemsets - deren Support überschreitet den minimalen Support - der Länge $k$. In der vorangegangenen Zelle wurde dementsprechend $L_1$ bestimmt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Generierung größerer Kandidatenmengen\n",
    "Die Menge $C_k$ wiederum bezeichnet im Folgenden alle in Frage kommenden Kandidaten-Itemsets der Länge $k$. Da dem Monotonie-Kriterium folgend nur die Itemsets der Länge $k$ betrachtet werden müssen, deren Teilmengen ebenfalls häufig sind, wird $C_k$ aus $L_{k-1}$ generiert. Itemsets der Länge $k-1$, die nicht in $L_{k-1}$ enthalten sind, kommen dagegen nicht häufig genug vor und wurden bereits zuvor ausgeschlossen. Sie erneut in Betracht zu ziehen hätte also keine Vorteile.\n",
    "\n",
    "Um $C_k$ aus $L_{k-1}$ zu generieren sind zwei Schritte notwendig:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Während des **Joins** werden die $k-1$-elementigen Itemsets aus der Menge $L_{k-1}$ zu $k$-elementigen Itemsets zusammengesetzt, sofern sie in den ersten $k-2$ Items übereinstimmen.\n",
    "\n",
    "Das nachfolgende Beispiel zeigt die Generierung eines $4$-Itemsets aus zwei $3$-Itemsets, welche die zuvor genannte Bedingung erfüllen.\n",
    "\n",
    "```\n",
    "e1: (Brot, Eier, Käse)\n",
    "                  ↓\n",
    "e2: (Brot, Eier,       Reis)\n",
    "                  ↓     ↓\n",
    "c:  (Brot, Eier, Käse, Reis)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Während des **Pruning** werden alle $k-1$-elementigen Teilmengen der entstandenen $k$-elementigen Itemsets betrachtet. Wenn auch nur eine dieser Teilmengen nicht in $L_{k-1}$ enthalten ist, kann das zugehörige $k$-elementige Itemset ebenfalls nicht häufig sein und kann ohne weiteren Aufwand direkt wieder verworfen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Der Algorithmus zum Generieren gestaltet sich zusammengesetzt wie folgt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def generiere_kandidaten(L, k):\n",
    "    # Join\n",
    "    all_C_k = set()\n",
    "\n",
    "    for e1 in L:\n",
    "        for e2 in L:\n",
    "            if e1.matches(e2, k-2):\n",
    "                all_C_k.add(e1.union(e2))\n",
    "\n",
    "    # Pruning\n",
    "    C_k = set()\n",
    "\n",
    "    for c in all_C_k:\n",
    "        for subset in c.subsets(k-1):\n",
    "            if subset not in L:\n",
    "                break\n",
    "        else:\n",
    "            C_k.add(c)\n",
    "\n",
    "    return C_k\n",
    "\n",
    "\n",
    "C2 = generiere_kandidaten(L1, 2)\n",
    "C2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Verständnisfrage:** Warum genügt es, Teilmengen zu kombinieren, die in den ersten $k-2$ Elementen übereinstimmen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Filtern nach minimalem Support\n",
    "Im Vergleich zu allen möglichen Teilmengen mit $k$ Elementen ist $C_k$ bereits relativ klein. Damit $C_{k+1}$ nicht aufgebläht wird, muss $C_k$ noch zu $L_k$ reduziert werden. Dafür wird der Support aller in $C_k$ enthaltenen, $k$-elementigen Teilmengen mit dem vorgegebenen, minimalen Support verglichen und entsprechend gefiltert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def filtere_kandidaten(C_k, transactions, min_supp):\n",
    "    return set(c for c in C_k if c.support_in(transactions) >= min_supp)\n",
    "\n",
    "\n",
    "L2 = filtere_kandidaten(C2, numbers, support_threshold)\n",
    "L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Finaler Algorithmus\n",
    "Der Algorithmus setzt die entworfenen Bausteine nun zusammen, um Schritt für Schritt größere Itemsets zu generieren, deren Support das gegebene Minimum überschreitet. Durch die Verwendung des Monotonie-Kriteriums sowie das Filtern in jedem Schritt wird unterbunden, dass die Anzahl der in Frage kommenden Itemsets zu groß wird.\n",
    "\n",
    "Der Algorithmus arbeitet dann wie folgt:\n",
    "1. Zuerst wird die Menge $L_1$ bestimmt, die alle Itemsets der Länge $1$ enthält, die den minimalen Support-Wert überschreiten.\n",
    "2. Solange die bereinigte Menge $L_{k-1}$ des vorhergehenden Durchlaufs nicht leer ist,\n",
    "    1. wird die Kandidatenmenge $C_k$ aus $L_{k-1}$ berechnet und\n",
    "    2. zu $L_k$ reduziert.\n",
    "3. Die Vereinigung aller erzeugten Mengen häufig vorkommender Itemsets $\\bigcup_i L_i$ ist das Ergebnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def apriori(transactions, min_supp):\n",
    "    # Liste der L_k anlegen\n",
    "    # mit leerer Menge als Padding\n",
    "    Ls = [set(), itemsets1(transactions, min_supp)]\n",
    "\n",
    "    # k initialisieren\n",
    "    k = 2\n",
    "\n",
    "    # Schleife\n",
    "    while len(Ls[-1]) > 0:\n",
    "        # Kandidatengenerierung und Filter\n",
    "        C_k = generiere_kandidaten(Ls[-1], k)\n",
    "        L_k = filtere_kandidaten(C_k, transactions, min_supp)\n",
    "\n",
    "        # L_k ablegen\n",
    "        Ls.append(L_k)\n",
    "\n",
    "        # k zählen\n",
    "        k += 1\n",
    "\n",
    "    # Vereinigung bilden\n",
    "    result = set()\n",
    "    for L in Ls:\n",
    "        result.update(L)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "apriori(numbers, support_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Einfluss des minimalen Supports\n",
    "Je höher der minimale Support ist, desto mehr Teilmengen werden im Laufe der Funktion `filtere_kandidaten` entfernt. Diese stehen dann natürlich auch nicht mehr im nächsten Schritt zu Verfügung, sodass erneut weniger Kandidaten generiert werden. Für die Laufzeit des Algorithmus wäre ein minimaler Support von $1$ also optimal. Gleichzeitig werden durch einen zu hohen Support allerdings Itemsets entfernt, die potentiell interessant sind.\n",
    "\n",
    "Der Wert für den minimalen Support sollte also so niedrig wie nötig und so hoch wie möglich gewählt werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
