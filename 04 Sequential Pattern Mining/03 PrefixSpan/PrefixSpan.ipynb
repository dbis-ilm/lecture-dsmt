{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69df3840-fba6-46eb-812a-32b57183e62a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# PrefixSpan\n",
    "PrefixSpan ist ein weiterer Algorithmus zum Auffinden häufiger Sequenzen in Transaktionsdatenbanken. Er extrahiert Sequenzmuster durch rekursives Vergrößern von Präfixen und versucht so das wiederholte, aufwendige Generieren und Prüfen von Kandidatenmengen zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b088f47-de98-468f-a13b-a751856bda83",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from tui_dsmt.fpm import SequentialItemset, dna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa1763-56d2-4114-a926-137c99ca1084",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Inhaltsverzeichnis\n",
    "- [Der Datensatz](#Der-Datensatz)\n",
    "- [Finden von einelementigen Sequenzen](#Finden-von-einelementigen-Sequenzen)\n",
    "- [Unterteilung des Suchraums](#Unterteilung-des-Suchraums)\n",
    "- [Sequenzen in Partitionen](#Sequenzen-in-Partitionen)\n",
    "- [Der finale Algorithmus](#Der-finale-Algorithmus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d8d532-899f-4c5d-91c7-8100eb644aa6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Der Datensatz\n",
    "Im Folgenden wird der Algorithmus anhand eines Beispiels veranschaulicht. Verwendet wird erneut die kleine Transaktionsdatenbank mit einigen fiktiven DNA-Sequenzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006f082-55e1-4701-a723-c78ea3b22830",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "dna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fba62d-1b45-493d-ba1d-4cd68cfe17c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Der Support wird wie bereits beim GSP-Algorithmus im Voraus festgelegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6fd5d3-d931-47e1-9eae-552401449b2e",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "min_supp = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eb6436-3a93-472d-b53e-4830d7983f15",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Finden von einelementigen Sequenzen\n",
    "Der erste Schritt ist erneut das Suchen von häufigen, einelementigen Sequenzen. In der Datenbank werden dazu - wie bereits mehrfach zuvor - alle Transaktionen gescannt, die 1-Itemsets gezählt und nach dem vorgebenen, minimalen Support gefiltert.\n",
    "\n",
    "Die nachfolgende Funktion kommt Ihnen deshalb vermutlich aus dem vorangegangenen Notebook bekannt vor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea1df2e-ccd9-48da-9763-816917d90be2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def itemsets1(transactions, min_supp):\n",
    "    # leere Abbildung anlegen\n",
    "    C1 = {}\n",
    "\n",
    "    # alle Transaktionen durchgehen\n",
    "    for _, items in transactions:\n",
    "        # alle Elemente der Transaktion betrachten\n",
    "        for element in items:\n",
    "            # Element zur Abbildung hinzufügen\n",
    "            # bzw. Anzahl um 1 erhöhen\n",
    "            if element not in C1:\n",
    "                C1[element] = 1\n",
    "            else:\n",
    "                C1[element] += 1\n",
    "\n",
    "    # Elemente nach minimalem Support filtern\n",
    "    # und in Itemset umwandeln\n",
    "    return set(SequentialItemset(item) for item, count in C1.items()\n",
    "               if count >= min_supp)\n",
    "\n",
    "\n",
    "F1 = itemsets1(dna, min_supp)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684ccb4-0f76-4667-bacc-c7c1756bf51f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Unterteilung des Suchraums\n",
    "Anhand der verbliebenen Sequenzen der Länge $1$ (nur `C` wurde auf Grund des minimalen Supports entfernt) wird der Suchraum für die weiteren Schritte partitioniert. Die Items dienen dabei als Präfix, sodass in der ersten Partition alle verbliebenen Optionen mit dem Präfix `A` untersucht werden sollen, in der zweiten Partition alle Optionen mit dem Präfix `G` und in der letzten Partition alle mit Präfix `T`.\n",
    "\n",
    "Die erste Transaktionsdatenbank besteht bisher aus allen verfügbaren (in diesem Fall $3$) unbeschnittenen DNA Sequenzen. Für die Partitionierung werden aus dieser sogenannte **projizierte Datenbanken** mit einem Präfix nach folgendem Schema hergeleitet:\n",
    "- Transaktionen, die das Präfix nicht enthalten, werden nicht in die projizierte Datenbank aufgenommen.\n",
    "- Transaktionen, welche das Präfix enthalten, werden ohne das Präfix übernommen.\n",
    "- Das erste vollständige Auftauchen des Präfix wird gewertet.\n",
    "\n",
    "Nach diesem Prinzip lassen sich zunächst einzelne Transaktionen projizieren:\n",
    "$$\n",
    "<A, C, B, C, A, D> \\; \\xrightarrow{A} \\; <C, B, C, A, D>\n",
    "$$$$\n",
    "<A, C, B, C, A, D> \\; \\xrightarrow{C} \\; <B, C, A, D>\n",
    "$$$$\n",
    "<A, C, B, C, A, D> \\; \\xrightarrow{C, B} \\; <C, A, D>\n",
    "$$\n",
    "\n",
    "Durch Hintereinanderausführung dieser Projektionen verlängert sich einfach das verwendete Präfix. Es ist daher nicht relevant, ob mit einem langen Präfix oder mit mehreren kurzen projiziert wird, sofern die Reihenfolge übereinstimmt:\n",
    "$$\n",
    "<A, C, B, C, A, D> \\; \\xrightarrow{C} \\; <B, C, A, D> \\; \\xrightarrow{B} \\; <C, A, D>\n",
    "$$\n",
    "\n",
    "Eine prozijierte Datenbank ist nun eine Transaktionsdatenbank, für die jede Transaktion nach dem gegebenen Präfix projiziert wurde. Im folgenden Beispiel wird die projizierte DNA-Datenbank für das Präfix `A` erzeugt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b5b1e-04e3-4f02-aed0-abdb221d07e2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "D_A = dna.project('A')\n",
    "D_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b851b8d-fcb1-4f32-9fa3-1be7cfcdd57c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Sequenzen in Partitionen\n",
    "Jede der entstandenen projizierten Datenbanken wird nun einzeln verarbeitet, indem innerhalb der verbliebenen Teiltransaktionen erneut nach häufigen, den minimalen Support überschreitenden Sequenzen der Länge $1$ gesucht wird. Diese Zählung schließt durch die zuvor erfolgte Projektion das verwendete Präfix implizit ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977bec78-b225-4fff-a7b1-106d8fa09442",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "itemsets1(D_A, min_supp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa356669-03bf-4855-869e-213dacb174d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Ausgehend von den gefundenen, häufigen Sequenzen der Länge $1$ unter Einbezug des angegebenen Präfix, werden erneut projizierte Datenbanken abgeleitet. Von diesem ausgehend wird der Algorithmus rekursiv fortgesetzt, bis in einem Schritt die projizierte Datenbank leer ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3dcf40-c886-417f-a571-c3d8aae38b91",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "D_AG = D_A.project('G')\n",
    "D_AG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ed016-5f3c-461b-9d2a-5664bc2fb5ec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das Paar leerer Klammern bedeutet, dass das Präfix in der Transaktion enthalten war, jedoch das Ende markierte und demnach eine leere Sequenz verbleibt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278de1b2-8eab-4fe7-8007-f862cab52141",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Der finale Algorithmus\n",
    "Der Algorithmus setzt die gezeigten Einzelschritte nun rekursiv zusammen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a682f00-47d3-4eab-a7a6-ab1af691f058",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def rec(D, min_supp, prefix=()):\n",
    "    # Häufige Sequenzen der Länge 1 finden.\n",
    "    frequent_sequences = itemsets1(D, min_supp)\n",
    "\n",
    "    # Jede häufige Sequenz der Länge 1 einzeln betrachten.\n",
    "    for sequence in frequent_sequences:\n",
    "        # Präfix mit häufiger Sequenz als (Zwischen-) Ergebnis zurückgeben.\n",
    "        yield prefix + sequence\n",
    "\n",
    "        # Datenbank projizieren, neues Präfix bilden, rekursiver Aufruf\n",
    "        projected_database = D.project(*sequence)\n",
    "        new_prefix = prefix + sequence\n",
    "        yield from rec(projected_database, min_supp, new_prefix)\n",
    "\n",
    "\n",
    "# Aufruf mit vollständiger Datenbank, min_supp und leerem Präfix\n",
    "set(rec(dna, min_supp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
