{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f17c8b8-b516-4a89-ba5c-1308a3f7679a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Generalized Sequential Pattern\n",
    "Der Generalized Sequential Pattern (GSP) Algorithmus ist ein beliebter Algorithmus im Bereich des Data Mining, der verwendet wird, um häufige Muster oder Sequenzen in einer Datenmenge zu finden. Der Algorithmus verwendet eine Monotonie-Eigenschaft und ist verwandt mit dem bereits bekannten Apriori-Algorithmus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e966bbd-5d7f-40f5-931b-1ffbe9d4cb3d",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from tui_dsmt.fpm import SequentialItemset, dna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d06c917-dca8-4d8c-9a62-9c624376aec0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Inhaltsverzeichnis\n",
    "- [Wiederholung: Monotonie-Eigenschaft](#Wiederholung-Monotonie-Eigenschaft)\n",
    "- [Der Algorithmus](#Der-Algorithmus)\n",
    "- [Zusammenfassung](#Zusammenfassung)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f3a46e-847b-4ce5-958e-ef80996e9eab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Wiederholung: Monotonie-Eigenschaft\n",
    "Die Monotonie-Eigenschaft besagte, dass jede Teilmenge eines häufig auftretenden Itemsets selbst häufig sein muss. Umgekehrt bedeutet dies, dass ein nicht-häufiges Itemset nicht mit einem beliebigen anderen Itemset zu einem häufigen, größeren Itemset vereinigt werden kann. Während des Apriori-Algorithmus konnte durch Ausschluss kleiner Itemsets somit eine Reduzierung des Suchraums auch im Hinblick auf größere Itemsets erreicht werden.\n",
    "\n",
    "Das Prinzip lässt sich ebenfalls auf Sequenzen anwenden. Jede Subsequenz einer häufig auftretenden Sequenz muss ebenfalls häufig sein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36383029-404f-4123-ad86-cbfb51566b22",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Der Algorithmus\n",
    "Betrachten Sie zuerst den Datensatz, der beispielhaft verwendet werden soll. Enthalten sind drei verschiedene (fiktive) DNA-Sequenzen, die im Folgenden auf gemeinsame Muster untersucht werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1adc7de-a64d-4cf8-9bd4-90650b001605",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "dna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa89b8ee-809d-4ff7-aafb-01015e7654dc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Der Algorithmus benötigt außerdem einen vorgegebenen, minimalen Support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f792cb-2ddc-447b-b237-aa4f9566299c",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "min_supp = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc354be-f100-4af4-a335-d474c1de9e8b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Bestimmung der einelementigen Sequenzen\n",
    "Analog zum Apriori-Algorithmus startet der GSP-Algorithmus mit der Suche nach Mustern der Länge $1$ und filtert diese mit Hilfe des minimalen Supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d6285-d14c-4457-bde9-aed9571b722d",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def itemsets1(transactions, min_supp):\n",
    "    # leere Abbildung anlegen\n",
    "    C1 = {}\n",
    "\n",
    "    # alle Transaktionen durchgehen\n",
    "    for _, items in transactions:\n",
    "        # alle Elemente der Transaktion betrachten\n",
    "        for element in items:\n",
    "            # Element zur Abbildung hinzufügen\n",
    "            # bzw. Anzahl um 1 erhöhen\n",
    "            if element not in C1:\n",
    "                C1[element] = 1\n",
    "            else:\n",
    "                C1[element] += 1\n",
    "\n",
    "    # Elemente nach minimalem Support filtern\n",
    "    # und in Itemset umwandeln\n",
    "    return set(SequentialItemset(item) for item, count in C1.items()\n",
    "               if count >= min_supp)\n",
    "\n",
    "\n",
    "L1 = itemsets1(dna, min_supp)\n",
    "L1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9de306-3bae-4a8c-b3d2-f3ba842cbb7d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Kandidatenmengen werden dabei wieder mit $C$ bezeichnet, während die zum selben Schritt gehörenden Mengen häufiger Sequenzen mit $F$ (statt $L$) bezeichnet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a324956d-95ae-4839-b7f2-0c8e387984c7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Generierung größerer Kandidatenmengen\n",
    "Während beim Apriori-Algorithmus immer zwei $k-1$-Itemsets, die sich unter Zuhilfenahme einer lexikographischen Ordnung in den ersten $k-2$ Elementen unterscheiden, zu einem $k$-Itemset zusammengeführt wurden, muss dieses Vorgehen beim GSP-Algorithmus angepasst werden. Ziel ist es jedoch erneut, aus mehreren $k-1$-Sequenzen neue $k$-Sequenzen zu erzeugen - und davon erneut möglichst wenige, die im weiteren Verlauf verworfen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c2136f-fad4-45d3-ae9d-c49ccae4e43c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Beispiel**:\n",
    "\n",
    "Sei $L_2 = \\{ (A, G), (A, T), (G, T) \\}$.\n",
    "\n",
    "Dann ist im Apriori-Algorithmus klar, dass als Kombination $(A, G, T)$ entsteht und $(A, G, T) \\in C_3$ gilt.\n",
    "\n",
    "Wird nicht nur nach häufigem gemeinsamen Auftreten gefragt, sondern Sequenzen unter Beibehaltung ihrer Reihenfolge gesucht, ergeben sich mehrere potentielle Kombinationen.\n",
    "- Da zwei der Sequenzen mit $A$ beginnen, wird eine entstehende Sequenz ebenfalls mit $A$ beginnen. An zweiter Stelle folgt dann **entweder** $G$ **oder** $T$, sodass für die dritte Stelle jeweils der nicht gewählte Buchstabe verbleibt. Es entstehen die Sequenzen $<\\!A, G, T\\!>$ und $<\\!A, T, G\\!>$.\n",
    "- Aus $<\\!A, T\\!>$ und $<\\!G, T\\!>$ entstehen mit ähnlicher Argumentation die Sequenzen $<\\!A, G, T\\!>$ und $<\\!G, A, T\\!>$.\n",
    "- Aus $<\\!A, G\\!>$ und $<\\!G, T\\!>$ entsteht die Sequenz $<\\!A, G, T\\!>$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e15628f-0776-4461-bb31-f480a1ed3dcb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Um keine unnötigen oder doppelten Sequenzen zu erzeugen, wird die **Join-Phase** wie folgt ausgeführt: Die Kandidatenmenge $C_k$ wird durch einen Verbund aus $L_{k-1}$ und $L_{k-1}$ erzeugt. Seien dafür $s_1, s_2 \\in L_{k-1}$. Ein neues Element $s_3$ wird erzeugt,\n",
    "- falls $s_1[2:k-1] = s_2[1:k-2]$ bzw. die erste Sequenz ohne das erste Item mit der zweiten Sequenz ohne das letzte Item übereinstimmt,\n",
    "- indem $s_3 = s_1 + s_2[k-1:k-1]$ bzw. das letzte Element von $s_2$ an $s_1$ angehangen wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cca4de-c1f9-46a6-b1f2-ac86c7f969b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Analog zum Apriori-Algorithmus existiert eine angehängte **Pruning-Phase**, die Kandidaten entfernt, die bereits ausgeschlossene Teilsequenzen enthalten. Dafür wird eine Sequenz der Länge $k$ wieder ausgeschlossen, falls sie eine $k-1$-Teilsequenz beinhaltet, die nicht in $L_{k-1}$ enthalten ist und damit nicht den minimalen Support erfüllt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc537e72-d447-4e00-8007-b1f0b6a4ac92",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die nachfolgende Zelle formuliert die beiden zuvor genannten Schritte in Python. Beachten Sie bitte, dass die Zählung in Python bei $0$ beginnt und der Endwert einer Slicing Operation nicht im Ergebnis enthalten ist, sodass die Indizes für Prä- und Suffixe jeweils angepasst werden müssen. (In Python können außerdem negative oder leere Start- und Endwerte verwendet werden. Wir verzichten hier darauf, um näher an der Definition zu bleiben.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4981149-8ffd-4671-8832-2a84946ffbfb",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def generiere_kandidaten(L, k):\n",
    "    # Join\n",
    "    all_C_k = set()\n",
    "\n",
    "    for s1 in L:\n",
    "        for s2 in L:\n",
    "            if s1[1:k-1] == s2[0:k-2]:\n",
    "                new_s = s1 + s2[k-2:k-1]\n",
    "                all_C_k.add(new_s)\n",
    "\n",
    "    # Pruning\n",
    "    C_k = set()\n",
    "\n",
    "    for c in all_C_k:\n",
    "        for subset in c.subsets(k-1):\n",
    "            if subset not in L:\n",
    "                break\n",
    "        else:\n",
    "            C_k.add(c)\n",
    "\n",
    "    return C_k\n",
    "\n",
    "\n",
    "C2 = generiere_kandidaten(L1, 2)\n",
    "C2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0588c0c-2901-40b3-9d9c-08a253df9ead",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Filtern nach minimalem Support\n",
    "Um $C_k$ zu $L_k$ zu reduzieren, wird erneut ein Scan der Datenbank durchgeführt und der Support aller in $C_k$ enthaltenen, $k$-elementigen Teilmengen mit dem vorgegebenen, minimalen Support verglichen und entsprechend gefiltert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff41e5-00d8-41e1-a471-687bec4901cb",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def filtere_kandidaten(C_k, transactions, min_supp):\n",
    "    return set(c for c in C_k if c.count_in(transactions) >= min_supp)\n",
    "\n",
    "\n",
    "L2 = filtere_kandidaten(C2, dna, min_supp)\n",
    "L2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8590a-0ecc-487d-9228-adf502c21b09",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Finaler Algorithmus\n",
    "Wie bereits zuvor werden die Bausteine zum finalen Algorithmus zusammengesetzt:\n",
    "1. Die Menge $L_1$ wird bestimmt, die alle Sequenzen der Länge $1$ enthält, die den minimalen Support-Wert überschreiten.\n",
    "2. Solange die bereinigte Menge $L_{k-1}$ nicht leer ist,\n",
    "    1. wird die Kandidatenmenge $C_k$ aus $L_{k-1}$ erzeugt und\n",
    "    2. zu $L_k$ reduziert.\n",
    "3. Die Vereinigung aller erzeugten Mengen häufig vorkommender Sequenzen $\\bigcup_i L_i$ ist das Ergebnis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71c5df-c9ab-405c-a457-922e5a8681c2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def gsp(transactions, min_supp):\n",
    "    # Liste der L_k anlegen\n",
    "    # mit leerer Menge als Padding\n",
    "    Ls = [set(), itemsets1(transactions, min_supp)]\n",
    "\n",
    "    # k initialisieren\n",
    "    k = 2\n",
    "\n",
    "    # Schleife\n",
    "    while len(Ls[-1]) > 0:\n",
    "        # Kandidatengenerierung und Filter\n",
    "        C_k = generiere_kandidaten(Ls[-1], k)\n",
    "        L_k = filtere_kandidaten(C_k, transactions, min_supp)\n",
    "\n",
    "        # L_k ablegen\n",
    "        Ls.append(L_k)\n",
    "\n",
    "        # k zählen\n",
    "        k += 1\n",
    "\n",
    "    # Vereinigung bilden\n",
    "    result = set()\n",
    "    for L in Ls:\n",
    "        result.update(L)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "gsp(dna, min_supp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aa9cab-8cfa-4dcc-b3eb-04a88d47b731",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Zusammenfassung\n",
    "Die Ähnlichkeit zum Apriori-Algorithmus ist offensichtlich, wobei die wichtigsten Unterschiede in der Kandidatengenerierung und dem Zählen der Vorkommen zu finden sind. Deshalb leidet der GSP-Algorithmus allerdings auch unter den selben Problemen: Es werden potentiell viele vollständige Scans der Datenbank benötigt und die Wahl des minimalen Supportwerts hat massiven Einfluss auf das Laufzeitverhalten des Algorithmus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
