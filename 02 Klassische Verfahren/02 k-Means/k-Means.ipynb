{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c175e00",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# k-Means\n",
    "Der k-Means-Algorithmus ist eines der beliebtesten Verfahren zur Clusteranalyse. Es lässt sich sehr einfach implementieren und findet schnell entsprechende Clusterzentren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bd644-0afc-401d-9a5b-9633eaa7f40b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tui_dsmt.clustering import animate_kmeans, interactive_kmeans\n",
    "from tui_dsmt.clustering.datasets import clustering_example1, clustering_example2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb97c64",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Inhaltsverzeichnis\n",
    "- [Der Algorithmus](#Der-Algorithmus)\n",
    "- [Visualisierung](#Visualisierung)\n",
    "- [Erweiterte Implementierungen](#Erweiterte-Implementierungen)\n",
    "- [Probleme](#Probleme)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b8f20",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Der Algorithmus\n",
    "k-Means verwendet sogenannte Zentroide, also künstliche Punkte, die als Repräsentanten für jeweils einen Cluster gelten. Das Ziel ist, eine feste Anzahl dieser Zentroide genau so zu verteilen, dass die Varianz innerhalb der Cluster möglichst gering wird. Es ist also ein Abstandsmaß notwendig, wobei im Folgenden die euklidische Distanz zur Anwendung kommt.\n",
    "\n",
    "Der Algorithmus verläuft wie folgt:\n",
    "1. Wähle $k$ Clusterzentren zufällig aus dem Datensatz. Die Anzahl $k$ muss also vorher bekannt sein.\n",
    "2. wiederhole bis zur Konvergenz:\n",
    "  1. Jeder Punkt wird dem Cluster zugeordnet, dessen Zentrum er am nächsten liegt.\n",
    "  2. Jedes Clusterzentrum wird als Mittelpunkt aller zugehörigen Punkte neu bestimmt.\n",
    "\n",
    "Die folgende Funktion arbeitet als Generator und gibt immer wieder neue Clusterzentren zurück, bis sie nicht mehr aufgerufen wird. Die Prüfung des Abbruchkriteriums fällt damit in die Verantwortung des aufrufenden Programmbestandteils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fdd0e0",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def k_means(xs, ys, k):\n",
    "    # Die Clusterzentren werden zufällig gewählt.\n",
    "    idx = np.random.choice(np.arange(len(xs)), k, replace=False)\n",
    "\n",
    "    centroids_x = xs[idx]\n",
    "    centroids_y = ys[idx]\n",
    "\n",
    "    yield centroids_x, centroids_y\n",
    "\n",
    "    # Die Clusterzentren werden wiederholt neu bestimmt.\n",
    "    while True:\n",
    "        # Die Variablen dienen dem Speichern der neuen\n",
    "        # Position der Clusterzentren.\n",
    "        new_centroids_x = np.zeros(k)\n",
    "        new_centroids_y = np.zeros(k)\n",
    "\n",
    "        centroids_len = np.zeros(k)\n",
    "\n",
    "        # Die Clusterzugehörigkeit wird für alle Punkte\n",
    "        # bestimmt.\n",
    "        for x, y in zip(xs, ys):\n",
    "            # Dazu wird die Distanz zu jedem Cluster-\n",
    "            # mittelpunkt berechnet. Das Minimum\n",
    "            # beschreibt den nahegelegendsten Cluster.\n",
    "            distances = np.sqrt((centroids_x - x) ** 2 + (centroids_y - y) ** 2)\n",
    "            centroid_index = distances.argmin()\n",
    "\n",
    "            # Die Koordinaten des Punktes werden zur\n",
    "            # Neubestimmung des Clusterzentrums\n",
    "            # gespeichert.\n",
    "            new_centroids_x[centroid_index] += x\n",
    "            new_centroids_y[centroid_index] += y\n",
    "\n",
    "            centroids_len[centroid_index] += 1\n",
    "\n",
    "        # Clustermittelpunkte, denen keine Punkte zu-\n",
    "        # geordnet wurden, werden erneut zufällig\n",
    "        # verteilt.\n",
    "        for i in range(len(centroids_len)):\n",
    "            if centroids_len[i] == 0:\n",
    "                new_centroids_x[i] = np.random.uniform(xs.min(), xs.max())\n",
    "                new_centroids_y[i] = np.random.uniform(ys.min(), ys.max())\n",
    "                centroids_len[i] = 1\n",
    "\n",
    "        # Die summierten Punkte werden durch die Anzahl\n",
    "        # geteilt, um neue Clustermittelpunkte zu\n",
    "        # erhalten.\n",
    "        centroids_x = new_centroids_x / centroids_len\n",
    "        centroids_y = new_centroids_y / centroids_len\n",
    "\n",
    "        yield centroids_x, centroids_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc46c3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Visualisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de55333b-a967-459d-925d-8f12a82986ad",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "animate_kmeans(k_means, clustering_example1, k=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15cb73a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Erweiterte Implementierungen\n",
    "Wie Sie gesehen haben, hängt der Algorithmus von der Initialisierung des Zufallszahlengenerators ab. Sie können daher beobachten, dass einige der Häufungen im äußeren Bereich aufgeteilt werden, während sich übergreifende Cluster in der Mitte bilden. Es kann sich daher lohnen, die Methode mehrfach auszuführen und das beste Ergebnis auszuwählen. Eine fertige Implementierung, die den k-Means-Algorithmus mehrfach ausführt und weitere Verbesserungen enthält, entstammt dem Paket `sklearn`.\n",
    "\n",
    "Initialisieren Sie dazu ein Objekt der Klasse `KMeans` und übergeben Sie dem Parameter die Anzahl der Clusterzentren. Rufen Sie anschließend `fit_predict` mit einem DataFrame auf, das die Angaben zu den entsprechenden Dimensionen enthält. Zurückgegeben wird ein Array aus Clusterindizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7780d4",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k = 15\n",
    "KMeans(k).fit_predict(clustering_example1[['x', 'y']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a90239-7ab1-4993-8ccf-e01db74e7fb9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In der nachfolgenden Zelle haben Sie die Möglichkeit mit dem Parameter $k$ zu experimentieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df2281-5342-47f6-8169-2d8ebc1d6759",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "interactive_kmeans(clustering_example1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a551962",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Probleme\n",
    "Der k-Means Algorithmus eignet sich jedoch nicht für alle Daten. Mengen, die nicht konvex sind, können beispielsweise nicht korrekt in Cluster eingeteilt werden. Die ineinandergreifenden Spiralen demonstrieren anschaulich die Grenzen des Algorithmus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db218558-92bd-4e2b-9a72-fabbbc13a96e",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "animate_kmeans(k_means, clustering_example2, k=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
