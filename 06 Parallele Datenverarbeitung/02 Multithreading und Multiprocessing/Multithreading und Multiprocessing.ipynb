{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a829a9-14d4-4ac7-a3cc-032218581d52",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Multithreading und Multiprocessing\n",
    "In diesem Abschnitt wird der Unterschied zwischen Threads und Prozessen erklärt. Weiterhin werden Umsetzungen in Python und Besonderheiten der Programmiersprache hinsichtlich der Parallelisierung gezeigt. Zuletzt wird ein alternatives Konzept der Nebenläufigkeit präsentiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b4a96-09df-4684-b953-cbc8c9520c15",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import multiprocessing\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "\n",
    "from tui_dsmt.parallel import mpi_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e86523e-843c-4404-abbc-021699e75873",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Inhaltsverzeichnis\n",
    "- [Threads und Prozesse](#Threads-und-Prozesse)\n",
    "- [Threads in Python und GIL](#Threads-in-Python-und-GIL)\n",
    "- [Prozesse in Python](#Prozesse-in-Python)\n",
    "- [Coroutinen](#Coroutinen)\n",
    "- [Message Parsing Interface (MPI)](#Message-Parsing-Interface-MPI)\n",
    "- [Zusammenfassung](#Zusammenfassung)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db50f8-a132-41e3-84b0-ab799874fb66",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Threads und Prozesse\n",
    "Threads und Prozesse sind grundlegende Konzepte, die zur nebenläufigen Ausführung von mehreren Aufgaben auf einem Computer verwendet werden.\n",
    "\n",
    "Ein Prozess ist eine eigenständige Ausführungseinheit, die einen eigenen Speicherbereich zugewiesen bekommt. Prozesse werden in der Regel vom Betriebssystem verwaltet, das sich um eben diese Zuweisung und die Aufteilung der Rechenzeit auf die existieren Prozesse kümmert. Die getrennten Speicherbereiche sorgen dafür, dass Prozesse voneinander isoliert ablaufen und sich gegenseitig - bei ausreichend vorhandener Rechenzeit - nicht beeinflussen.\n",
    "\n",
    "Ein Thread hingegen ist eine Ausführungseinheit innerhalb eines Prozesses. Die Threads eines Prozesses teilen sich gemeinsam den Speicherbereich des Prozesses und können nach Belieben aus diesem lesen und schreiben. Threads gelten außerdem als *leichter*, weil sie weniger Overhead erzeugen, da kein separater Speicher reserviert werden muss, und weil sie schneller zu erzeugen und zu zerstören sind als vollwertige Prozesse. Die Zuteilung der Rechenleistung erfolgt bei Threads in der Regel auch durch das Betriebssystem, es existieren allerdings auch [andere Implementierungen](https://en.wikipedia.org/wiki/Green_thread) mit eigenen Vor- und Nachteilen.\n",
    "\n",
    "Die Zusammenarbeit mehrerer Threads ist in der Regel einfach, da ein Datensatz oder Zwischenergebnisse nur einmal im Speicher liegen muss und alle Threads nach Belieben auf diesen Speicher zugreifen können. Das Teilen von Speicher macht die Algorithmen jedoch anfälliger gegenüber Korruption und Race Conditions. Die Zusammenarbeit mehrerer Prozesse muss dagegen mit Hilfe einer Interprozesskommunikationmethode realisiert werden, um Teile des Speicherinhalts wie Daten oder Zwischenergebnisse an andere Prozesse zu versenden. Interprozesskommunikation ist dabei immer langsamer als geteilter Speicher.\n",
    "\n",
    "Die Verwendung mehrerer Prozesse ist beim Aufteilen der parallelen Arbeit auf mehrere, durch ein Netzwerk verbundene Computer alternativlos, da kein gemeinsamer Hauptspeicher existiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d168a-0fec-4eed-b4e5-fef0312019e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Threads in Python und GIL\n",
    "In Python können Threads mit dem `threading`-Modul erstellt werden. Das nachfolgende Beispiel erstellt zwei Threads, die parallel arbeiten und jeweils eine bestimmte Sequenz ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd12a6-6bd2-490a-b9ab-b4f81107fdac",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def print_seq(sequence):\n",
    "    for i in sequence:\n",
    "        print(i)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# Erzeugen der Threads\n",
    "thread1 = threading.Thread(target=print_seq, args=(range(1, 5),))\n",
    "thread2 = threading.Thread(target=print_seq, args=('abcd',))\n",
    "\n",
    "# Starten der Threads (im Hintergrund)\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Warten auf Beenden der Threads / Funktionen\n",
    "thread1.join()\n",
    "thread2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea085c63-7e06-4e3f-82b2-7af11c6ab102",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Erwartungsgemäß sollten abwechselnd Ziffern und Buchstaben ausgegeben werden. In der Realität ist die Zuweisung der Rechenzeit aber von so vielen Faktoren abhängig, dass die genaue Reihenfolge nicht vorhersehbar ist. Beim wiederholten Ausführen werden Sie feststellen, dass kleine Abweichungen wie das Vertauschen von Buchstabe und Ziffer und in seltenen Fällen auch zwei Einträge pro Zeile gefolgt von einer Leerzeile vorkommen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ff197-3e99-45b5-aeb0-4d5fb882bb3d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In Abhängigkeit der vorhandenen Hardware verlangsamt es die Berechnung möglicherweise, zu viele Threads anzulegen. Python hält mit dem `ThreadPoolExecutor` auch dafür eine Lösung bereit: Diesem kann eine beliebige Anzahl an Aufgaben übergeben werden, die in einer festen Anzahl an Threads abgearbeitet werden. Sobald ein Thread mit einer Aufgabe fertig ist, übernimmt er die nächste. Durch die Verwendung als Kontext-Manager wird die Shutdown Methode nach Ende des Blocks automatisch aufgerufen und die Übergabe weiterer Aufgaben blockiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff40f4-1703-4168-bad0-784752d89224",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "with ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    executor.submit(print_seq, range(1, 5))\n",
    "    executor.submit(print_seq, 'abcd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759ed3f6-314c-46b7-a0d8-a29a10f6224a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In Python existiert zudem mit dem sogenannten *Global Interpreter Lock* (GIL) ein Mechanismus, der dafür sorgt, dass immer nur ein Thread Python-Code ausführen kann. Dies bedeutet, dass selbst in einem Multithreading-Programm mit mehreren Threads, nur ein Thread zur gleichen Zeit auf dem Prozessor ausgeführt wird. Die nachfolgenden Zellen verdeutlichen das Problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546d7ba7-b69d-45ef-81cb-1e22b06b050a",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def cpu_bound_task():\n",
    "    counter = 0\n",
    "    while counter < 10_000_000:\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e213f8-a047-47e6-aecc-74ed86176335",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Sequentielle Ausführung von zwei Durchläufen\n",
    "cpu_bound_task()\n",
    "cpu_bound_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbb290-3216-46cd-8b30-ee933165ffd2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Parallele Ausführung in zwei Threads\n",
    "threads = [threading.Thread(target=cpu_bound_task) for _ in range(2)]\n",
    "for t in threads: t.start()\n",
    "for t in threads: t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a000f-df9b-4855-a8b8-21053332d67f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Erwartungsgemäß sollte die parallele Ausführung nur etwa die Hälfte der Zeit benötigen, da die Arbeit auf zwei Threads verteilt wird. Was in vielen Programmiersprachen genau so funktioniert, benötigt durch den GIL in Python dennoch die selbe Zeit wie die sequentielle Ausführung. Die Verwendung von Threads lohnt sich mit Python daher nur, wenn die Threads nicht durch den Prozessor limitiert werden, sondern z.B. durch das Lesen von Daten von der Festplatte oder durch Kommunikation mit dem Netzwerk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d93a4-8233-4e2c-bd09-210b81b7cb41",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die [Entfernung des GIL](https://heise.de/-9655663 ) ist aktuell ein Ziel bei der Weiterentwicklung der Sprache."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee289af5-e968-4872-86a6-48f4ec3e9390",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Prozesse in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65da2e1-1f4c-4bb1-8ac6-66b0cd4c9da3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Um parallele Ausführungen mit mehreren Prozessen in Python zu demonstrieren, verwenden wir das `multiprocessing`-Modul. Dieses Modul ermöglicht es uns, unabhängige Prozesse zu erstellen, die in separaten Speicherbereichen jeweils einen eigenen Python-Interpreter ausführen. Die nachfolgende Zelle demonstriert die Verwendung von Prozessen anstelle von Threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f984c-41f7-4e86-8761-a78374cdfc6a",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def print_seq(sequence):\n",
    "    for i in sequence:\n",
    "        print(i)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "# Erzeugen der Prozesse\n",
    "proc1 = multiprocessing.Process(target=print_seq, args=(range(1, 5),))\n",
    "proc2 = multiprocessing.Process(target=print_seq, args=('abcd',))\n",
    "\n",
    "# Starten der Prozesse (im Hintergrund)\n",
    "proc1.start()\n",
    "proc2.start()\n",
    "\n",
    "# Warten auf Beenden der Prozesse\n",
    "proc1.join()\n",
    "proc2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ac2b3-4f86-4436-965e-98f1e72fe1fb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Da die Prozesse keinen gemeinsamen Speicher verwenden, können auch keine Variablen zwischen den Aufgaben geteilt werden, um Ergebnisse zu kommunizieren. Aus dem `multiprocessing`-Modul stehen aber spezielle Objekte bereit, um diesem Umstand zu begegnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd870e-5450-4d35-a9cb-74ae5919727a",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def in_process(result):\n",
    "    result[1] = 'a'\n",
    "\n",
    "result_dict = multiprocessing.Manager().dict()\n",
    "\n",
    "proc = multiprocessing.Process(target=in_process, args=(result_dict,))\n",
    "proc.start()\n",
    "proc.join()\n",
    "\n",
    "result_dict.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a0620-abb7-474e-b9f3-52d9a72e2561",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "An den nachfolgenden Zellen können Sie nachvollziehen, dass die Prozesse tatsächlich unabhängig voneinander arbeiten und insbesondere nicht durch den Global Interpreter Lock (GIL) eingeschränkt sind. Die parallel ausgeführten Prozesse benötigen für die gleichen Operationen in etwas über die Hälfte der Zeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc22a24-ab0f-4e17-a1ff-be028efda6d9",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Sequentielle Ausführung von zwei Durchläufen\n",
    "cpu_bound_task()\n",
    "cpu_bound_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eab50d-ae6f-4dc7-b5c1-73d7edf119c4",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Parallele Ausführung in zwei Prozessen\n",
    "procs = [multiprocessing.Process(target=cpu_bound_task) for _ in range(2)]\n",
    "for p in procs: p.start()\n",
    "for p in procs: p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c43ce64-955b-432c-b692-f1f88dfeca7e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Auch für Prozesse steht ein Executor bereit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58357e07-58e0-40cc-9ccb-a7370a27a043",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "with ProcessPoolExecutor(max_workers=1) as executor:\n",
    "    executor.submit(print_seq, range(1, 5))\n",
    "    executor.submit(print_seq, 'abcd')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fb20ae-39cc-4331-ac3c-96eb64eb08ab",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Coroutinen\n",
    "Python unterstützt außerdem Coroutinen, die einen speziellen Ansatz der Nebenläufigkeit umsetzen. In Threads ablaufende Aufgaben bekommen Rechenzeit vom Betriebssystem zugewiesen und können demnach jederzeit unterbrochen werden. Coroutinen hingegen verzichten an geeigneten Stellen freiwillig auf Rechenzeit und geben die Kontrolle an andere Coroutinen ab, während sie alle in einem gemeinsamen Thread laufen.\n",
    "\n",
    "Coroutinen besitzen damit noch weniger Overhead als Threads. Sie benötigen nur Speicher für ihren Funktionsaufruf und den aktuellen Stack und auch Kontextwechsel sind deutlich schneller, sodass man mit ausreichend Arbeitsspeicher problemlos zehntausende von ihnen innerhalb einer Anwendung erzeugen kann. Da alle Coroutinen in einem gemeinsamen Thread laufen, teilen sie sich aber Eigenschaften mit dem GIL: Tatsächlich Python-Code ausführen kann immer nur eine einzige Coroutine, sodass der Einsatz nur bei Aufgaben dienlich ist, die einen großen Teil ihrer Zeit mit dem *Warten* auf das Netzwerk oder Festspeicher verbringen.\n",
    "\n",
    "Geeignete Stellen für das Unterbrechen ist also genau dieses Warten auf Objekte, die langsamer als der Prozessor sind. Ein weiterer Vorteil des Aussuchens der Unterbrechung liegt weiterhin in weniger Seiteneffekten, die auftreten können, und einer verbesserten Lesbarkeit des Codes gegenüber Threads: Der Quellcode lässt sich überwiegend wie sequentieller Code lesen, auch wenn er tatsächlich Nebenläufigkeit erlaubt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9783de-0006-4f9b-8cc2-ee5cf9dec462",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In Python steht in der Standardinstalltion für Coroutinen das Modul `asyncio` bereit, das zusammen mit den Schlüsselwörtern `async` und `await` die Programmierung von Coroutinen erlaubt. Der Unterschied einer normalen zu einer asynchronen Methode ist dabei, dass der Aufruf zunächst normal aussieht, allerdings ein Objekt vom Typ `coroutine` zurückgibt. Innerhalb dieser Methoden (und innerhalb von Jupyter Zellen) kann außerdem das Schlüsselwort `await` verwendet werden, um auf das Ergebnis einer Coroutine zu warten. Es markiert gleichzeitig die Möglichkeit zur Übernahme von Rechenzeit durch andere Coroutinen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df6f04-412e-4c0f-90a9-a0abfeebd1e5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "async def async_print_seq(sequence):\n",
    "    for i in sequence:\n",
    "        print(i)\n",
    "        await asyncio.sleep(0.5)\n",
    "\n",
    "async_print_seq(range(1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d7f26-d46a-4ba2-9cf9-ef839e4b533f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Der Aufruf mehrere Funktionen, die parallel ablaufen, kann dann beispielsweise mit `gather` erfolgen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002048bc-d320-4569-93e1-a72499fd23d5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "await asyncio.gather(*(\n",
    "    async_print_seq(range(1, 5)),\n",
    "    async_print_seq('abcd')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445c10c-677e-4ea1-b1ec-c872a9b0f6a1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Verständnisfrage**: Bei der Verwendung von Threads und Prozessen wurden gelegentlich\n",
    "- Ziffer und Buchstabe in ihrer Reihenfolge vertauscht oder\n",
    "- zwei Werte pro Zeile ausgegeben.\n",
    "\n",
    "Kann das mit Coroutinen ebenfalls vorkommen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc70fc22-cae0-4c27-beb2-9f9a48519e0f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Message Parsing Interface (MPI)\n",
    "MPI ist ein Standard für die parallele Programmierung auf verteilten Systemen mit lokalem Speicher. Entwickelt wurde der Standard in den 90er Jahren mit dem Ziel, eine portable und skalierbare Möglichkeit für parallele Programmierung zu schaffen, sodass es sich sowohl in einem durch ein Netzwerk verbundenes Cluster-System wie auch lokal mit mehreren Prozessen verwenden lässt. MPI stellt insbesondere Möglichkeiten bereit, um verschiedene Arten Nachrichten zwischen Prozessen auszutauschen, und gilt daher als sehr flexibel. So sind nicht nur Punkt-zu-Punkt Nachrichten möglich, sondern auch Broadcasts, Barrieren und Remote Memory Access.\n",
    "\n",
    "Anwendung findet MPI daher in vielen verschiedenen Bereichen, insbesondere in der Simulation physikalischer Modelle, wie Wetter- und Klimamodellierung, Molekulardynamik oder Strömungsmechanik. Für Python existieren mehrere Bibliotheken, welche die Funktionalität von MPI verfügbar machen. Im Folgenden sollen kurz die relevantesten Operationen mit `mpi4py` gezeigt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b625f031-7a6b-4e81-ba5f-819f354dae16",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Zum Starten mehrerer Prozesse, die mit Hilfe von MPI zusammenarbeiten, muss MPI auf allen beteiligten Systemen installiert sein. Weitere Systeme lassen sich dann zum Beispiel über SSH zum Cluster hinzufügen, das Ausführen ist aber auch auf dem lokalen System mit mehreren Prozessen möglich. Zum Starten wird in der Regel `mpiexec` oder `mpirun` verwendet. Um in einem Terminal vier Python Prozesse zu starten, die untereinander mit MPI kommunizieren, kann das nachfolgende Kommando verwendet werden:\n",
    "\n",
    "```bash\n",
    "mpiexec -n 4 python3 script.py\n",
    "```\n",
    "\n",
    "Da wir im Folgenden die Jupyter Umgebung nicht verlassen wollen, steht eine Funktion `mpi_run` bereit, die einen lokalen Cluster erzeugt und **eine** übergebene Python Funktion ausführt. Die nachfolgende Zelle zeigt zudem die Verwendung von `Get_rank()`, das die ID des aktuellen Prozess zurückgibt, und `Get_size()`, das die Anzahl aller Prozesse liefert. Da alle Prozesse den selben Code ausführen, lassen sich mit diesen Funktionen Fallunterscheidungen treffen, um verschiedenen Prozessen verschiedene Aufgabenteile zuzuweisen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db60b5f5-d0a8-4cfe-852b-fd014ee5c43f",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def mpi_fun():\n",
    "    from mpi4py import MPI\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank, size = comm.Get_rank(), comm.Get_size()\n",
    "\n",
    "    return f'Hallo Welt von Prozess {rank} von {size}'\n",
    "\n",
    "mpi_run(mpi_fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4fdf27-eeb5-4acd-b2ff-5c61796ec798",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nachrichten zwischen zwei spezifischen Prozessen lassen sich mit den Funktionen `send` und `recv` austauschen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b6d14-6720-4ed0-9d28-0eaacc744d5c",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def mpi_fun():\n",
    "    from mpi4py import MPI\n",
    "    import random\n",
    "\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank, size = comm.Get_rank(), comm.Get_size()\n",
    "\n",
    "    if rank == 0:\n",
    "        random_num = random.randint(1, 20)\n",
    "        comm.send(random_num, dest=1)\n",
    "        return f'Prozess {rank} schickt {random_num}'\n",
    "\n",
    "    if rank == 1:\n",
    "        random_num = comm.recv(source=0)\n",
    "        return f'Prozess {rank} empfängt {random_num}'\n",
    "\n",
    "mpi_run(mpi_fun, num_proc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0ab0f-d76d-4537-8bf2-00f19a452b53",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Es lassen sich aber mit `bcast` auch Nachrichten an alle (anderen) Teilnehmer schicken. Die nachfolgende Zelle demonstriert zudem eine weitere Funktion von `mpi4py`: Es lassen sich nicht nur primitive Datentypen verschicken. Komplexere Typen werden automatisch mit Pickle serialisiert und deserialisiert, sodass auch das Versenden von Objekten, Listen, etc. möglich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f67ee2-fdd2-4a3f-888c-4ec5333acfe9",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def mpi_fun():\n",
    "    from mpi4py import MPI\n",
    "    import random\n",
    "\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank, size = comm.Get_rank(), comm.Get_size()\n",
    "\n",
    "    # Objekt initialisieren\n",
    "    random_obj = None\n",
    "\n",
    "    # Objekt auf erstem Prozess vorbereiten\n",
    "    if rank == 0:\n",
    "        random_obj = {\n",
    "            'zahl': random.randint(1, 20),\n",
    "            'buchstabe': random.choice('abcdefgh')\n",
    "        }\n",
    "\n",
    "    # Broadcast aufrufen, Quelle ist Prozess 0\n",
    "    random_obj = comm.bcast(random_obj, root=0)\n",
    "    return f'Prozess {rank} empfängt {random_obj}'\n",
    "\n",
    "mpi_run(mpi_fun, num_proc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2619539-438b-44cb-80e5-27a9a2dbe2a2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Barrieren sind Synchronisationspunkte, an denen jeder Prozess wartet, bis die Barriere von allen Prozessen erreicht wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d8d72-cb1a-4676-9d85-710ed235c5c1",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def mpi_fun():\n",
    "    from mpi4py import MPI\n",
    "    import time\n",
    "\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank, size = comm.Get_rank(), comm.Get_size()\n",
    "\n",
    "    # Startzeit speichern\n",
    "    start = time.time()\n",
    "\n",
    "    # unterschiedlich lang schlafen\n",
    "    sleep_time = rank * 1.5\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    # Barriere einsetzen\n",
    "    comm.Barrier()\n",
    "\n",
    "    # verbrachte Zeit zurückgeben\n",
    "    time_spent = time.time() - start\n",
    "    return f'Prozess {rank} schlief {sleep_time}s und endete nach {time_spent}s'\n",
    "\n",
    "mpi_run(mpi_fun, num_proc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2201d9-3422-471a-9d3d-49f24350f2f5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "MPI stellt viele weitere Funktionen bereit, unter anderem Locks, Windows / Remote Memory Access und verteilte I/O Operationen, die allesamt verwendet werden können, um MPI Programme effizienter zu gestalten, und ebenfalls von `mpi4py` unterstützt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd11761-3d43-4d58-a3a5-cb31de12728b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Zusammenfassung\n",
    "In Python stehen verschiedene Methoden bereit, um Nebenläufigkeit zu erzeugen. Das Erzeugen von Prozessen und Threads reicht aber lang nicht aus, um produktiv parallele Programme zu entwickeln. So muss sich um eine korrekte Aufgabenteilung gekümmert, Prozesse synchronisiert, Zwischenergebnisse kommuniziert und nach Möglichkeit eine Lastverteilung vorgenommen werden. MPI ist eine Bibliothek, welche die dafür notwendigen Funktionen für eine Vielzahl von Programmiersprachen standardisiert.\n",
    "\n",
    "Beim Ablauf paralleler Programme können außerdem Probleme auftreten, die bei sequentiellen Programmen nicht vorkommen können, so zum Beispiel Race Conditions, Deadlocks oder auch Konsistenzprobleme (bspw. Lost Updates). Nachfolgend sollen daher Modelle präsentiert werden, die bei Zutreffen bestimmer Annahmen die Programmierung vereinfachen und gleichzeitig derartige Fehler vermeiden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
